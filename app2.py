import numpy as np
import pandas as pd
import streamlit as st

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import xgboost
from PIL import Image
import plotly.graph_objs as go

##########################
# 1. Utility Functions   #
##########################

def AL_RandomForest(trainX, trainY, testX, testY, n_estimators=400, max_depth=None, random_state=42):
    rf_clf = RandomForestRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state
    )
    rf_clf.fit(trainX, trainY)
    y_pred2 = rf_clf.predict(testX)
    return y_pred2

def AL_GradientBoosting(trainX, trainY, testX, testY,
                        n_estimators=200, learning_rate=0.04, max_depth=2, random_state=42):
    # Temporarily rename columns as integers to avoid fitting errors
    trainX.columns = pd.RangeIndex(trainX.shape[1])
    testX.columns = pd.RangeIndex(testX.shape[1])

    gbr_model = GradientBoostingRegressor(
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        max_depth=max_depth,
        random_state=random_state
    )
    gbr_model.fit(trainX, trainY)
    y_pred2 = gbr_model.predict(testX)
    return y_pred2

def AL_XGBoosting(trainX, trainY, testX, testY,
                  n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42):
    # Temporarily rename columns as integers to avoid fitting errors
    trainX.columns = pd.RangeIndex(trainX.shape[1])
    testX.columns = pd.RangeIndex(testX.shape[1])

    xgb_model = xgboost.XGBRegressor(
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        max_depth=max_depth,
        random_state=random_state
    )
    xgb_model.fit(trainX, trainY)
    y_pred2 = xgb_model.predict(testX)
    return y_pred2

def AL_SVR(trainX, trainY, testX, testY):
    # ë§Œì•½ SVRì—ì„œë„ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê³  ì‹¶ë‹¤ë©´, ë™ì¼í•˜ê²Œ íŒŒë¼ë¯¸í„° ì¶”ê°€ ê°€ëŠ¥
    trainX.columns = pd.RangeIndex(trainX.shape[1])
    testX.columns = pd.RangeIndex(testX.shape[1])

    sv_regressor = SVR(kernel='linear', C=3, epsilon=0.03)
    sv_regressor.fit(trainX, trainY)
    y_pred2 = sv_regressor.predict(testX)
    return y_pred2

def Performance_index(obs, pre, mod_str):
    if mod_str == 'R2':
        pf_index = r2_score(obs, pre)
    elif mod_str == 'RMSE':
        pf_index = np.sqrt(mean_squared_error(obs, pre))
    elif mod_str == 'MSE':
        pf_index = mean_squared_error(obs, pre)
    elif mod_str == 'MAE':
        pf_index = mean_absolute_error(obs, pre)
    return pf_index

##########################
# 2. Streamlit App       #
##########################

# -- Images/Logos
im = Image.open("AI_Lab_logo.jpg")
im2 = Image.open("mangan_intro.jpg")

# -- Page Config
st.set_page_config(
    page_title="ë§ê°„ ìˆ˜ì§ˆ ì˜ˆì¸¡(Manganese Prediction)",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# -- Sidebar Header
with st.sidebar:
    st.image(im, width=150)
    st.title("ë§ê°„ ìˆ˜ì§ˆì˜ˆì¸¡")
    st.write("---")

    # Checkbox for sample data
    load_data = st.checkbox("ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© (ì£¼ì•”ëŒ)", value=False)
    if not load_data:
        file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
    else:
        # When checked, use default dataset file name
        file = "dataset_cleaned.csv"

    st.write("---")

# -- Main Title / Intro Section
st.title("ğŸ“Š Manganese Water Quality Prediction Model")
st.markdown(
    """
    On this page, we use models such as RandomForest, GradientBoosting, and XGBoost to predict the concentration of Manganese (Mn).
    Please follow the steps below in order:
    ì €ìˆ˜ì§€ ìˆ˜ì§ˆì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ë¨¸ì‹ ëŸ¬ë‹(RandomForest, GradientBoosting, XGBoost) ëª¨ë¸ ì ìš© 
    1. Upload your dataset or select the sample data
      (ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒ˜í”Œ ë°ì´í„° ì„ íƒ)
    2. Specify the date column and the target variable (Manganese concentration)
      (ë‚ ì§œ ì»¬ëŸ¼, ì¢…ì†ë³€ìˆ˜(ì˜ˆì¸¡ë³€ìˆ˜ ë†ë„) ì„¤ì •)  
    3. ë¶„ì„ ëª¨ë¸ ì„ íƒ ë° ê²°ê³¼ í™•ì¸(ëˆ„ì ë¨, í•˜ì´í¼íŒŒë¼ë¯¸í„°ë„ ì¡°ì • ê°€ëŠ¥)  
       Choose an analysis model and view the results 
       (hyperparameter tuning is also available)
    ---
    """
)

# -- Image Placeholder
placeholder = st.empty()
if file == "dataset_cleaned.csv":
    placeholder.image(im2, use_column_width=True)

# -- session_stateì— ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ê³µê°„ ì¤€ë¹„
if "simulation_results" not in st.session_state:
    # simulation_results ë‚´ë¶€ì— (ëª¨ë¸ ì´ë¦„, ì‹¤ì œê°’, ì˜ˆì¸¡ê°’, í•˜ì´í¼íŒŒë¼ë¯¸í„° dict) í˜•íƒœë¡œ ì €ì¥
    st.session_state["simulation_results"] = []

# -- If data file is provided or sample is chosen
if file:
    try:
        data = pd.read_csv(file)
    except Exception as e:
        st.warning("CSV íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ë™ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        st.stop()

    with st.expander("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=False):
        st.dataframe(data.head(5), use_container_width=True)

    st.write("---")

    # -- Column Selection Expander
    with st.expander("1) ë‚ ì§œ ì»¬ëŸ¼ ë° ë§ê°„(ì¢…ì†ë³€ìˆ˜) ì„¤ì •", expanded=True):
        # Multi-select for columns that might be used
        columns_list = st.multiselect(
            "ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”",
            data.columns.tolist(),
            default=data.columns.tolist()
        )

        if len(columns_list) < 2:
            st.warning("ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ë¥¼ ëª¨ë‘ í¬í•¨í•˜ë„ë¡ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            # Select date column
            date_col = st.selectbox(
                "ë‚ ì§œ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
                options=columns_list
            )

            # Select target column (Manganese)
            y_var = st.selectbox(
                "ì¢…ì†ë³€ìˆ˜(ë§ê°„ ë†ë„) ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
                options=[col for col in columns_list if col != date_col],
                index=0
            )

    st.write("---")

    # -- Check if user has selected columns properly
    if 'date_col' in locals() and 'y_var' in locals() and date_col and y_var:
        # Data Preprocessing
        with st.expander("2) ë°ì´í„° ì „ì²˜ë¦¬(Scaling, ë‚ ì§œ ì²˜ë¦¬)", expanded=True):
            st.write("âœ… ì„ íƒëœ ë‚ ì§œ ì»¬ëŸ¼: ", date_col)
            st.write("âœ… ì„ íƒëœ ì¢…ì†ë³€ìˆ˜(ë§ê°„ ë†ë„): ", y_var)

            # Rename, handle date
            data = data.rename(columns={date_col: "set_date"})
            data['set_date'] = pd.to_datetime(data['set_date'], errors='coerce')
            # Extract month as a float feature
            data['month'] = data['set_date'].dt.month.astype(float)
            # Remove rows with missing values
            data = data.dropna(subset=["set_date", y_var])  

            # Scale all numeric columns except 'set_date'
            numeric_cols = data.select_dtypes(include=np.number).columns.tolist()
            if 'set_date' in numeric_cols:
                numeric_cols.remove('set_date')

            # MinMaxScaler
            scaler = MinMaxScaler()
            scaled_data = data.copy()
            scaled_data[numeric_cols] = scaler.fit_transform(scaled_data[numeric_cols])

            st.markdown("**ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**")
            st.dataframe(scaled_data.head(5), use_container_width=True)

        # Prepare data for modeling
        # Drop date column from final training
        final_data = scaled_data.drop(['set_date'], axis=1)
        X = final_data.drop([y_var], axis=1)
        y = final_data[y_var]

        # Train/Test Split
        trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2, random_state=42)

        # -- Model Selection
        model_list = ["Random Forest", "Gradient Boosting", "XGBoost"]
        performance_list = ["RMSE", "R2", "MSE", "MAE"]

        with st.expander("3) ëª¨ë¸ ì„ íƒ ë° ì˜ˆì¸¡ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •)", expanded=True):
            selected_model = st.selectbox("ì˜ˆì¸¡ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", model_list)

            # ëª¨ë¸ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë ¥ ì˜ì—­
            st.markdown("**í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •**")
            if selected_model == "Random Forest":
                n_estimators = st.number_input("n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)", min_value=50, max_value=2000, value=300, step=50)
                max_depth = st.number_input("max_depth (íŠ¸ë¦¬ ê¹Šì´)", min_value=1, max_value=100, value=5, step=1)
                # íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
                param_dict = {
                    "n_estimators": n_estimators,
                    "max_depth": max_depth
                }
            elif selected_model == "Gradient Boosting":
                n_estimators = st.number_input("n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)", min_value=50, max_value=2000, value=300, step=50)
                learning_rate = st.slider("learning_rate", min_value=0.001, max_value=1.0, value=0.04, step=0.01)
                max_depth = st.number_input("max_depth (íŠ¸ë¦¬ ê¹Šì´)", min_value=1, max_value=50, value=2, step=1)
                param_dict = {
                    "n_estimators": n_estimators,
                    "learning_rate": learning_rate,
                    "max_depth": max_depth
                }
            elif selected_model == "XGBoost":
                n_estimators = st.number_input("n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)", min_value=50, max_value=2000, value=500, step=50)
                learning_rate = st.slider("learning_rate", min_value=0.001, max_value=1.0, value=0.05, step=0.01)
                max_depth = st.number_input("max_depth (íŠ¸ë¦¬ ê¹Šì´)", min_value=1, max_value=50, value=3, step=1)
                param_dict = {
                    "n_estimators": n_estimators,
                    "learning_rate": learning_rate,
                    "max_depth": max_depth
                }
            else:
                param_dict = {}

            # Run training only when the user clicks this button
            if st.button("ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡í•˜ê¸°"):
                if selected_model == "Random Forest":
                    yhat = AL_RandomForest(trainX, trainY, testX, testY,
                                           n_estimators=param_dict["n_estimators"],
                                           max_depth=param_dict["max_depth"])
                elif selected_model == "Gradient Boosting":
                    yhat = AL_GradientBoosting(trainX, trainY, testX, testY,
                                               n_estimators=param_dict["n_estimators"],
                                               learning_rate=param_dict["learning_rate"],
                                               max_depth=param_dict["max_depth"])
                elif selected_model == "XGBoost":
                    yhat = AL_XGBoosting(trainX, trainY, testX, testY,
                                         n_estimators=param_dict["n_estimators"],
                                         learning_rate=param_dict["learning_rate"],
                                         max_depth=param_dict["max_depth"])
                else:
                    st.warning("ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    st.stop()

                # ìµœê·¼ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥ (append)
                st.session_state["simulation_results"].append(
                    (selected_model, testY.values, yhat, param_dict)
                )

                st.success(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ëª¨ë¸: {selected_model}")

    else:
        st.warning("ë‚ ì§œ ì»¬ëŸ¼ê³¼ ì¢…ì†ë³€ìˆ˜(ë§ê°„) ì»¬ëŸ¼ì„ ì˜¬ë°”ë¥´ê²Œ ì„ íƒí•´ì£¼ì„¸ìš”.")

# -- ì´ì œ session_stateì— ëˆ„ì ëœ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ í‘œì‹œ
# -- 'ê°€ì¥ ìµœê·¼ ì‹œë®¬ë ˆì´ì…˜'ì´ ë§¨ ìœ„, ì˜¤ë˜ëœ ê²ƒì´ ì•„ë˜ê°€ ë˜ë„ë¡ reversed() í™œìš©
if len(st.session_state["simulation_results"]) > 0:
    st.write("---")
    st.subheader("ğŸ“ˆ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼(ëˆ„ì )")

    # reversed()ë¥¼ ì‚¬ìš©í•´ ë§ˆì§€ë§‰ì— ì¶”ê°€ëœ(ê°€ì¥ ìµœê·¼) ì‹œë®¬ë ˆì´ì…˜ë¶€í„° í‘œì‹œ
    total_sims = len(st.session_state["simulation_results"])
    for idx, (model_name, actual_vals, pred_vals, used_params) in enumerate(reversed(st.session_state["simulation_results"]), start=1):
        # ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ë²ˆí˜¸(ì²˜ìŒ ì‹œë„ = #1, ê°€ì¥ ìµœê·¼ = #n)
        # reversedë¡œ ì¶œë ¥í•˜ë¯€ë¡œ, í™”ë©´ì—ëŠ” #n(ê°€ì¥ ìµœì‹ ), #n-1, ... , #1(ê°€ì¥ ì˜¤ë˜ëœ) ìˆœìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
        sim_number = total_sims - idx + 1  

        st.markdown(f"### â–¶ ì‹œë®¬ë ˆì´ì…˜ #{sim_number} (ëª¨ë¸: {model_name})")
        if used_params:
            st.write("**ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°:**", used_params)

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        performance_list = ["RMSE", "R2", "MSE", "MAE"]
        cols = st.columns(4)
        for i, pi in enumerate(performance_list):
            score = Performance_index(actual_vals, pred_vals, pi)
            cols[i].metric(label=pi, value=f"{score:.4f}")
        
        # ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë˜í”„
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(actual_vals)),
                y=actual_vals,
                mode='lines+markers',
                name='Actual',
                line=dict(color='green')
            )
        )
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(pred_vals)),
                y=pred_vals,
                mode='lines+markers',
                name='Predicted',
                line=dict(color='red')
            )
        )
        fig.update_layout(
            xaxis_title='Data Index(#)',
            yaxis_title='Concentration(mg/L)',
            legend=dict(orientation='h', y=1.1),
            autosize=True,
            width=1200,
            height=400,
            margin=dict(l=10, r=10, t=10, b=10),
            plot_bgcolor='white',
            paper_bgcolor='white',
            xaxis=dict(showline=True, linewidth=2, linecolor='black'),
            yaxis=dict(showline=True, linewidth=2, linecolor='black')
        )
        st.plotly_chart(fig, use_container_width=True)

# -- Footer / Credits
st.write("---")
st.markdown(
    """
    <p style='text-align: center; color: grey;'>
      â“’ 2025 K-water AI Lab. All rights reserved.  
      | ë¬¸ì˜: <a href='mailto:sunghoonkim@kwater.or.kr'>sunghoonkim@kwater.or.kr</a>
    </p>
    """,
    unsafe_allow_html=True
)
