import numpy as np
import pandas as pd
import streamlit as st

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import xgboost
from PIL import Image
import plotly.graph_objs as go

##########################
# 1. Utility Functions   #
##########################

def AL_RandomForest(trainX, trainY, testX, testY, n_estimators=400, max_depth=None, random_state=42):
    rf_clf = RandomForestRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state
    )
    rf_clf.fit(trainX, trainY)
    y_pred2 = rf_clf.predict(testX)
    return y_pred2

def AL_GradientBoosting(trainX, trainY, testX, testY,
                        n_estimators=200, learning_rate=0.04, max_depth=2, random_state=42):
    # (ì¶”ê°€) ì»¬ëŸ¼ì´ objectì¼ ê²½ìš° ìˆ«ìí˜•ìœ¼ë¡œ í•œì •
    trainX.columns = pd.RangeIndex(trainX.shape[1])
    testX.columns  = pd.RangeIndex(testX.shape[1])

    gbr_model = GradientBoostingRegressor(
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        max_depth=max_depth,
        random_state=random_state
    )
    gbr_model.fit(trainX, trainY)
    y_pred2 = gbr_model.predict(testX)
    return y_pred2

def AL_XGBoosting(trainX, trainY, testX, testY,
                  n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42):
    trainX.columns = pd.RangeIndex(trainX.shape[1])
    testX.columns  = pd.RangeIndex(testX.shape[1])

    xgb_model = xgboost.XGBRegressor(
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        max_depth=max_depth,
        random_state=random_state
    )
    xgb_model.fit(trainX, trainY)
    y_pred2 = xgb_model.predict(testX)
    return y_pred2

def AL_SVR(trainX, trainY, testX, testY):
    trainX.columns = pd.RangeIndex(trainX.shape[1])
    testX.columns  = pd.RangeIndex(testX.shape[1])

    sv_regressor = SVR(kernel='linear', C=3, epsilon=0.03)
    sv_regressor.fit(trainX, trainY)
    y_pred2 = sv_regressor.predict(testX)
    return y_pred2

def Performance_index(obs, pre, mod_str):
    if mod_str == 'R2':
        pf_index = r2_score(obs, pre)
    elif mod_str == 'RMSE':
        pf_index = np.sqrt(mean_squared_error(obs, pre))
    elif mod_str == 'MSE':
        pf_index = mean_squared_error(obs, pre)
    elif mod_str == 'MAE':
        pf_index = mean_absolute_error(obs, pre)
    return pf_index


##########################
# 2. Streamlit App       #
##########################

# -- Images/Logos
im = Image.open("AI_Lab_logo.jpg")
im2 = Image.open("mangan_intro.jpg")

# -- Page Config
st.set_page_config(
    page_title="ë§ê°„ ìˆ˜ì§ˆ ì˜ˆì¸¡(Manganese Prediction)",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# -- Sidebar Header
with st.sidebar:
    st.image(im, width=150)
    st.title("ë§ê°„ ìˆ˜ì§ˆì˜ˆì¸¡")
    st.write("---")

    # Checkbox for sample data
    load_data = st.checkbox("Dam(JA) data", value=False)
    if not load_data:
        file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
    else:
        file = "dataset_cleaned.csv"

    st.write("---")

# -- Main Title / Intro Section
st.title("ğŸ“Š Manganese Water Quality Prediction Model")
st.markdown(
    """
    On this page, we use models such as RandomForest, GradientBoosting, and XGBoost to predict the concentration of Manganese (Mn).
    Please follow the steps below in order:
    ì €ìˆ˜ì§€ ìˆ˜ì§ˆì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ë¨¸ì‹ ëŸ¬ë‹(RandomForest, GradientBoosting, XGBoost) ëª¨ë¸ ì ìš© 
    1. Upload your dataset or select the sample data  
    2. Specify the date column and the target variable (Manganese concentration)  
    3. Choose an analysis model and view the results (hyperparameter tuning is also available)
    ---
    """
)

# -- (1) í† ê¸€ë¡œ "mangan_intro.jpg" ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤„ì§€ ë§ì§€ ê²°ì •
show_main_image = st.checkbox("Show *Introduction*", value=True)
if show_main_image:
    st.image(im2, use_column_width=True)

# -- session_stateì— ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ê³µê°„ ì¤€ë¹„
if "simulation_results" not in st.session_state:
    st.session_state["simulation_results"] = []

# -- íŒŒì¼ì´ ì¤€ë¹„ëì„ ê²½ìš° ë¡œì§ ì‹¤í–‰
if file:
    try:
        data = pd.read_csv(file)
    except Exception as e:
        st.warning("CSV íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ë™ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        st.stop()

    # -- (2) ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=False):
        st.dataframe(data.head(5), use_container_width=True)

    st.write("---")

    # -- Column Selection
    with st.expander("1) ë‚ ì§œ ì»¬ëŸ¼ ë° ë§ê°„(ì¢…ì†ë³€ìˆ˜) ì„¤ì •", expanded=True):
        columns_list = st.multiselect(
            "ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”",
            data.columns.tolist(),
            default=data.columns.tolist()
        )

        if len(columns_list) < 2:
            st.warning("ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ë¥¼ ëª¨ë‘ í¬í•¨í•˜ë„ë¡ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            date_col = st.selectbox(
                "ë‚ ì§œ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
                options=columns_list
            )
            y_var = st.selectbox(
                "ì¢…ì†ë³€ìˆ˜(ë§ê°„ ë†ë„) ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
                options=[col for col in columns_list if col != date_col],
                index=0
            )

    st.write("---")

    if 'date_col' in locals() and 'y_var' in locals() and date_col and y_var:
        # 2) ë°ì´í„° ì „ì²˜ë¦¬
        with st.expander("2) ğŸ” ë°ì´í„° ì „ì²˜ë¦¬(Scaling, ë‚ ì§œ ì²˜ë¦¬)", expanded=True):
            st.write("âœ… ì„ íƒëœ ë‚ ì§œ ì»¬ëŸ¼: ", date_col)
            st.write("âœ… ì„ íƒëœ ì¢…ì†ë³€ìˆ˜(ë§ê°„ ë†ë„): ", y_var)

            data = data.rename(columns={date_col: "set_date"})
            data['set_date'] = pd.to_datetime(data['set_date'], errors='coerce')
            data['month'] = data['set_date'].dt.month.astype(float)
            data = data.dropna(subset=["set_date", y_var])

            numeric_cols = data.select_dtypes(include=np.number).columns.tolist()
            if 'set_date' in numeric_cols:
                numeric_cols.remove('set_date')

            scaler = MinMaxScaler()
            scaled_data = data.copy()
            scaled_data[numeric_cols] = scaler.fit_transform(scaled_data[numeric_cols])

            st.markdown("**ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**")
            st.dataframe(scaled_data.head(5), use_container_width=True)

        # -- ìµœì¢… ë°ì´í„°ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ ì œì™¸
        final_data = scaled_data.drop(['set_date'], axis=1)
        X = final_data.drop([y_var], axis=1)
        y = final_data[y_var]

        # -- Train/Test Split
        trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2, random_state=42)

        ########################################################################
        # (ì¤‘ìš”) NaN / Inf ì œê±° & ìˆ«ìí˜• ì¹¼ëŸ¼ë§Œ ì‚¬ìš©
        ########################################################################
        # 1) ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        trainX = trainX.select_dtypes(include=[np.number])
        testX  = testX.select_dtypes(include=[np.number])

        # 2) Inf -> NaN ë³€í™˜
        trainX = trainX.replace([np.inf, -np.inf], np.nan)
        testX  = testX.replace([np.inf, -np.inf], np.nan)

        # 3) NaNì´ ìˆëŠ” í–‰ ì œê±° (X, Y ë™ê¸°í™”)
        #    trainXê°€ NaNì¸ í–‰ => trainYì—ì„œë„ ê°™ì€ index ì œê±°
        before_train_size = len(trainX)
        train_mask = trainX.notnull().all(axis=1)  # ëª¨ë“  ì¹¼ëŸ¼ì´ notnullì¸ í–‰ë§Œ True
        trainX = trainX[train_mask]
        trainY = trainY[train_mask]
        after_train_size = len(trainX)

        # testë„ ë™ì¼í•˜ê²Œ
        before_test_size = len(testX)
        test_mask = testX.notnull().all(axis=1)
        testX = testX[test_mask]
        testY = testY[test_mask]
        after_test_size = len(testX)

        # -- ë¡œê·¸ë¡œ í™•ì¸í•´ë³¼ ìˆ˜ë„ ìˆìŒ
        st.write(f"Train Data: {before_train_size} -> {after_train_size} (rows after drop NaN/Inf)")
        st.write(f"Test  Data: {before_test_size} -> {after_test_size} (rows after drop NaN/Inf)")

        ########################################################################
        # ì´í›„ ëª¨ë¸ í•™ìŠµ
        ########################################################################
        model_list = ["Random Forest", "Gradient Boosting", "XGBoost"]
        performance_list = ["RMSE", "R2", "MSE", "MAE"]

        with st.expander("3) ëª¨ë¸ ì„ íƒ ë° ì˜ˆì¸¡ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •)", expanded=True):
            selected_model = st.selectbox("ì˜ˆì¸¡ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", model_list)

            st.markdown("**í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •**")
            if selected_model == "Random Forest":
                n_estimators = st.number_input("n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)", min_value=50, max_value=2000, value=300, step=50)
                max_depth = st.number_input("max_depth (íŠ¸ë¦¬ ê¹Šì´)", min_value=1, max_value=100, value=5, step=1)
                param_dict = {
                    "n_estimators": n_estimators,
                    "max_depth": max_depth
                }
            elif selected_model == "Gradient Boosting":
                n_estimators = st.number_input("n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)", min_value=50, max_value=2000, value=300, step=50)
                learning_rate = st.slider("learning_rate", min_value=0.001, max_value=1.0, value=0.04, step=0.01)
                max_depth = st.number_input("max_depth (íŠ¸ë¦¬ ê¹Šì´)", min_value=1, max_value=50, value=2, step=1)
                param_dict = {
                    "n_estimators": n_estimators,
                    "learning_rate": learning_rate,
                    "max_depth": max_depth
                }
            elif selected_model == "XGBoost":
                n_estimators = st.number_input("n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)", min_value=50, max_value=2000, value=500, step=50)
                learning_rate = st.slider("learning_rate", min_value=0.001, max_value=1.0, value=0.05, step=0.01)
                max_depth = st.number_input("max_depth (íŠ¸ë¦¬ ê¹Šì´)", min_value=1, max_value=50, value=3, step=1)
                param_dict = {
                    "n_estimators": n_estimators,
                    "learning_rate": learning_rate,
                    "max_depth": max_depth
                }
            else:
                param_dict = {}

            if st.button("ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡í•˜ê¸°"):
                if selected_model == "Random Forest":
                    yhat = AL_RandomForest(trainX, trainY, testX, testY,
                                           n_estimators=param_dict["n_estimators"],
                                           max_depth=param_dict["max_depth"])
                elif selected_model == "Gradient Boosting":
                    yhat = AL_GradientBoosting(trainX, trainY, testX, testY,
                                               n_estimators=param_dict["n_estimators"],
                                               learning_rate=param_dict["learning_rate"],
                                               max_depth=param_dict["max_depth"])
                elif selected_model == "XGBoost":
                    yhat = AL_XGBoosting(trainX, trainY, testX, testY,
                                         n_estimators=param_dict["n_estimators"],
                                         learning_rate=param_dict["learning_rate"],
                                         max_depth=param_dict["max_depth"])
                else:
                    st.warning("ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    st.stop()

                st.session_state["simulation_results"].append(
                    (selected_model, testY.values, yhat, param_dict)
                )
                st.success(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ëª¨ë¸: {selected_model}")

    else:
        st.warning("ë‚ ì§œ ì»¬ëŸ¼ê³¼ ì¢…ì†ë³€ìˆ˜(ë§ê°„) ì»¬ëŸ¼ì„ ì˜¬ë°”ë¥´ê²Œ ì„ íƒí•´ì£¼ì„¸ìš”.")

# -- ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í‘œì‹œ
if len(st.session_state["simulation_results"]) > 0:
    st.write("---")
    st.subheader("ğŸ“ˆ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼(ëˆ„ì )")

    total_sims = len(st.session_state["simulation_results"])
    for idx, (model_name, actual_vals, pred_vals, used_params) in enumerate(reversed(st.session_state["simulation_results"]), start=1):
        sim_number = total_sims - idx + 1  
        st.markdown(f"### â–¶ ì‹œë®¬ë ˆì´ì…˜ #{sim_number} (ëª¨ë¸: {model_name})")
        if used_params:
            st.write("**ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°:**", used_params)

        performance_list = ["RMSE", "R2", "MSE", "MAE"]
        cols = st.columns(4)
        for i, pi in enumerate(performance_list):
            score = Performance_index(actual_vals, pred_vals, pi)
            cols[i].metric(label=pi, value=f"{score:.4f}")
        
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(actual_vals)),
                y=actual_vals,
                mode='lines+markers',
                name='Actual',
                line=dict(color='green')
            )
        )
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(pred_vals)),
                y=pred_vals,
                mode='lines+markers',
                name='Predicted',
                line=dict(color='red')
            )
        )
        fig.update_layout(
            xaxis_title='Data Index(#)',
            yaxis_title='Concentration(mg/L)',
            legend=dict(orientation='h', y=1.1),
            autosize=True,
            width=1200,
            height=400,
            margin=dict(l=10, r=10, t=10, b=10),
            plot_bgcolor='white',
            paper_bgcolor='white',
            xaxis=dict(showline=True, linewidth=2, linecolor='black'),
            yaxis=dict(showline=True, linewidth=2, linecolor='black')
        )
        st.plotly_chart(fig, use_container_width=True)

# -- Footer / Credits
st.write("---")
st.markdown(
    """
    <p style='text-align: center; color: grey;'>
      â“’ 2025 K-water AI Lab. All rights reserved.  
      | ë¬¸ì˜: <a href='mailto:sunghoonkim@kwater.or.kr'>sunghoonkim@kwater.or.kr</a>
    </p>
    """,
    unsafe_allow_html=True
)
